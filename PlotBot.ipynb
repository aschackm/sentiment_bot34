{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Bot (@sentiment_bot34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import tweepy\n",
    "import time\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy\n",
    "from datetime import datetime\n",
    "from matplotlib import style\n",
    "style.use('ggplot')\n",
    "from config import consumer_key, consumer_secret, access_token, access_token_secret\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twitter API Keys\n",
    "consumer_key = consumer_key\n",
    "consumer_secret = consumer_secret\n",
    "access_token = access_token\n",
    "access_token_secret = access_token_secret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twitter Credentials\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, parser=tweepy.parsers.JSONParser())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function that pulls mentions and past posts from Twitter, then analyzes past posts of another user and posts findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_plot():\n",
    "    # Bot can be found at https://twitter.com/sentiment_bot34 (It will most likely be non functional but tweets of graphs will be visable)\n",
    "    bot_handle = \"@sentiment_bot34\"\n",
    "    request_list = []\n",
    "    print(\"Running function\")\n",
    "    \n",
    "    # Search for tweets mentioning bot handle\n",
    "    public_tweets = api.search(bot_handle, count=20, result_type=\"recent\")\n",
    "    print(\"Searching for mentions\")\n",
    "    \n",
    "    # Extracting id, author, and target user from tweets\n",
    "    for tweet in public_tweets[\"statuses\"]:\n",
    "\n",
    "        tweet_id = tweet[\"id\"]\n",
    "        tweet_author = tweet[\"user\"][\"screen_name\"]\n",
    "    \n",
    "        for mentions in tweet[\"entities\"][\"user_mentions\"]:\n",
    "\n",
    "            request_list.append(mentions[\"screen_name\"])\n",
    "        print(\"Extracted search info\")\n",
    "        \n",
    "    # Dropping duplicate requests by converting to set then back\n",
    "    target_requests = set(request_list)\n",
    "    target_requests = list(target_requests)\n",
    "    #print(f\"target_requests = {target_requests}\")\n",
    " \n",
    "    # Check bot timeline for past analysis to prevent repeated use on same user\n",
    "    timeline_tweets = api.user_timeline()\n",
    "    for tweet in timeline_tweets:\n",
    "        for mentions in tweet[\"entities\"][\"user_mentions\"]:\n",
    "            user = (mentions[\"screen_name\"])\n",
    "            #print(f\"user = {user}\")\n",
    "            for target in target_requests:\n",
    "                #print(target)\n",
    "                if target == user:\n",
    "                    target_requests.remove(target)\n",
    "                    print(f\"{user} has already been analyzed\")\n",
    "                elif target == \"sentiment_bot34\":\n",
    "                    target_requests.remove(target)\n",
    "                    print(\"Skipping analysis on sentiment_bot34 itself\")\n",
    "\n",
    "    print(f\"Requested targets: {target_requests}\")    \n",
    "    for target in target_requests:\n",
    "        print(\"Beginning analysis\")\n",
    "        target_user = f\"@{target}\"\n",
    "        counter = 1\n",
    "        sentiments = []\n",
    "        oldest_tweet = None\n",
    "\n",
    "    # Loop through 25 pages of tweets (total 500 tweets)\n",
    "        for x in range(25):\n",
    "            public_tweets = api.user_timeline(target_user, max_id = oldest_tweet)\n",
    "            #print(f\"Getting {target_user}'s tweets\")\n",
    "    # Sentiment analysis\n",
    "            for tweet in public_tweets:\n",
    "                results = analyzer.polarity_scores(tweet[\"text\"])\n",
    "                compound = results[\"compound\"]\n",
    "                pos = results[\"pos\"]\n",
    "                neu = results[\"neu\"]\n",
    "                neg = results[\"neg\"]\n",
    "                tweets_ago = counter\n",
    "                #print(\"Analyzing tweets\")\n",
    "    # Get Tweet ID, subtract 1, and assign to oldest_tweet\n",
    "                oldest_tweet = tweet['id'] - 1\n",
    "\n",
    "    # Add sentiments for each tweet into a list\n",
    "                sentiments.append({\"Date\": tweet[\"created_at\"], \n",
    "                                  \"Compound\": compound,\n",
    "                                  \"Positive\": pos,\n",
    "                                  \"Negative\": neu,\n",
    "                                  \"Neutral\": neg,\n",
    "                                  \"Tweets Ago\": counter})\n",
    "                counter += 1\n",
    "\n",
    "    # Convert sentiments to DataFrame\n",
    "        print(\"Creating dataframe\")\n",
    "        sentiments_pd = pd.DataFrame.from_dict(sentiments)\n",
    "        #sentiments_pd.head()\n",
    "\n",
    "    # Plot of sentiments\n",
    "        x_vals = sentiments_pd[\"Tweets Ago\"]\n",
    "        y_vals = sentiments_pd[\"Compound\"]\n",
    "        plt.plot(x_vals, y_vals, marker=\"o\", linewidth=0.5, alpha=0.8, color=\"blue\")\n",
    "        now = datetime.now()\n",
    "        now = now.strftime(\"%Y-%m-%d %H:%M\")\n",
    "        plt.title(\"Sentiment Analysis of Tweets \\n (\" + now + \") for \" + target_user)\n",
    "        plt.xlim([x_vals.max(),x_vals.min()])\n",
    "        plt.ylim(-1,1)\n",
    "        plt.ylabel(\"Tweet Polarity\")\n",
    "        plt.xlabel(\"Tweets Ago\")\n",
    "        plt.gcf().subplots_adjust(left=0.15)\n",
    "        plt.savefig(f\"{target_user}.png\")  \n",
    "        print(\"Plotting tweets\")\n",
    "    # Post to Twitter\n",
    "        try:\n",
    "            print(\"Posting to Twitter\")\n",
    "            api.update_with_media(f\"{target_user}.png\",\n",
    "                          f\"@%s Here is a sentiment analysis of {target_user}\" % tweet_author, in_reply_to_status_id=tweet_id)   \n",
    "        except tweepy.TweepError as e:\n",
    "            print(e.reason)\n",
    "            continue\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running function every 5 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running function\n",
      "Searching for mentions\n",
      "Extracted search info\n",
      "Extracted search info\n",
      "Extracted search info\n",
      "Extracted search info\n",
      "Extracted search info\n",
      "AlexSchackmuth has already been analyzed\n",
      "Skipping analysis on sentiment_bot34 itself\n",
      "guardian has already been analyzed\n",
      "nytpolitics has already been analyzed\n",
      "nytimes has already been analyzed\n",
      "NYTMetro has already been analyzed\n",
      "Requested targets: []\n",
      "Running function\n",
      "Searching for mentions\n",
      "Extracted search info\n",
      "Extracted search info\n",
      "Extracted search info\n",
      "Extracted search info\n",
      "Extracted search info\n",
      "Extracted search info\n",
      "Extracted search info\n",
      "Extracted search info\n",
      "AlexSchackmuth has already been analyzed\n",
      "Skipping analysis on sentiment_bot34 itself\n",
      "guardian has already been analyzed\n",
      "nytpolitics has already been analyzed\n",
      "nytimes has already been analyzed\n",
      "NYTMetro has already been analyzed\n",
      "Requested targets: ['reneauberjonois', 'realGulDukat', 'BarackObama']\n",
      "Beginning analysis\n",
      "Creating dataframe\n",
      "Plotting tweets\n",
      "Posting to Twitter\n",
      "Beginning analysis\n",
      "Creating dataframe\n",
      "Plotting tweets\n",
      "Posting to Twitter\n",
      "Beginning analysis\n",
      "Creating dataframe\n",
      "Plotting tweets\n",
      "Posting to Twitter\n"
     ]
    }
   ],
   "source": [
    "# Set timer to run every 5 minutes\n",
    "while(True):\n",
    "    sentiment_plot()\n",
    "    time.sleep(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
